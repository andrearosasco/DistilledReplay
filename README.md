# Distilled Replay
[![LICENSE](https://img.shields.io/badge/license-MIT-green?style=flat-square)](https://github.com/andrew-r96/DistilledReplay/blob/main/LICENSE)
[![Python](https://img.shields.io/badge/python-3.8-blue.svg?style=flat-square)](https://www.python.org/) 

### Paper
- Distilled Replay: Overcaming Forgetting through Synthetic Samples,
2021. \[[PDF](https://arxiv.org/pdf/2103.15851.pdf)\]


### Setup & Execution
- Install the packages listed in requirements.txt

- Run the desired configuration file (e.g. python smnist_continual_distillation/config_dr.py will run Distilled Replay on Split MNIST)


### Citation

Please cite our paper if it is helpful to your work:

```bibtex
@article{Rosasco2021DR,
  author    = {Andrea, Rosasco and Antonio, Carta and Andrea, Cossu and Vincenzo, Lomonaco and Davide, Bacciu},
  title     = {Distilled Replay: Overcaming Forgetting through Synthetic Samples},
  journal = {arXiv},
  year      = {2021}
}
```

